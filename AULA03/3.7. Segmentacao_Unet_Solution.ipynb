{"cells":[{"cell_type":"markdown","id":"4d97e80f","metadata":{"id":"4d97e80f"},"source":["# 1. Introdução\n","\n","Neste notebook usamos uma rede U-Net (ou semelhante) pré-treinada para aplicar segmentação semântica em uma imagem real.\n","\n","Vamos utilizar um modelo da `torchvision` (DeepLabV3+ com ResNet50) como exemplo prático."]},{"cell_type":"code","execution_count":null,"id":"8b7bf939","metadata":{"id":"8b7bf939"},"outputs":[],"source":["# Instalar pacotes (se necessário no Colab)\n","# !pip install torchvision matplotlib\n","import torch\n","import torchvision.transforms as T\n","from torchvision.models.segmentation import deeplabv3_resnet50\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","import cv2\n"]},{"cell_type":"code","source":["# Verifica se já foram baixadas as imagens do drive, baixando-as e descompactando se necessário\n","! [ ! -d \"/content/cachorro.jpeg\" ] && gdown -O /content/cachorro.jpeg \"1xQdpWJ4fU7RUMltryqeNqaF31gKhYYzZ\"\n","\n","! [ ! -d \"/content/carro.jpg\" ] && gdown -O /content/carro.jpg \"16F9AkZybPG3ppcoOboYlfvRmTK0g77wV\"\n","\n","! [ ! -d \"/content/pessoas.jpg\" ] && gdown -O /content/pessoas.jpg \"19Q9M_vCwIxyUK4C45F2ZjRZcKUoBUugq\"\n"],"metadata":{"id":"XsnrLkd-0TlW"},"id":"XsnrLkd-0TlW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"cfb7cb84","metadata":{"id":"cfb7cb84"},"outputs":[],"source":["# Carregar modelo pré-treinado (21 classes da PASCAL VOC)\n","model = deeplabv3_resnet50(pretrained=True)\n","model.eval();"]},{"cell_type":"code","source":["# Mapear classes para cores\n","def decode_segmap(image, nc=21):\n","    # Mapa de cores: cada índice de classe (0 a 20) é associado a uma cor RGB.\n","    # Isso permite que cada classe seja representada visualmente por uma cor distinta.\n","    label_colors = np.array([\n","        (0, 0, 0),\n","        (128, 0, 0),\n","        (0, 128, 0),\n","        (128, 128, 0),\n","        (0, 0, 128),\n","        (128, 0, 128),\n","        (0, 128, 128),\n","        (128, 128, 128),\n","        (64, 0, 0),\n","        (192, 0, 0),\n","        (64, 128, 0),\n","        (192, 128, 0),\n","        (64, 0, 128),\n","        (192, 0, 128),\n","        (64, 128, 128),\n","        (192, 128, 128),\n","        (0, 64, 0),\n","        (128, 64, 0),\n","        (0, 192, 0),\n","        (128, 192, 0),\n","        (0, 64, 128)\n","    ])\n","\n","    # Cria 3 matrizes vazias do mesmo tamanho da imagem de classes (H×W), para os canais RGB\n","    r = np.zeros_like(image).astype(np.uint8)  # canal vermelho\n","    g = np.zeros_like(image).astype(np.uint8)  # canal verde\n","    b = np.zeros_like(image).astype(np.uint8)  # canal azul\n","\n","    # Para cada classe l (de 0 até nc-1):\n","    for l in range(0, nc):\n","        # Cria uma máscara booleana onde a imagem de classes == l\n","        idx = image == l\n","        if idx.any():\n","          print(l)\n","\n","        # Preenche os canais RGB nas posições onde a classe é l, com a cor correspondente\n","        r[idx] = label_colors[l, 0]\n","        g[idx] = label_colors[l, 1]\n","        b[idx] = label_colors[l, 2]\n","\n","    # Empilha os canais r, g, b em um único array 3D com shape (H, W, 3)\n","    rgb = np.stack([r, g, b], axis=2)\n","\n","    return rgb"],"metadata":{"id":"mEYwOfF81TFN"},"id":"mEYwOfF81TFN","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"fa6addb9","metadata":{"id":"fa6addb9"},"outputs":[],"source":["# Carregar imagem (ex: pessoa, animal, vegetação)\n","img_path = 'cachorro.jpeg'\n","# img_path = 'pessoas.jpg'\n","# img_path = 'carro.jpg'\n","\n","img = Image.open(img_path).convert('RGB')\n","\n","# Pré-processamento\n","preprocess = T.Compose([\n","    T.Resize(256),\n","    T.CenterCrop(224),\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","input_tensor = preprocess(img).unsqueeze(0)  # shape: (1, 3, H, W)\n","\n","display(img)\n","\n","# Fazer inferência\n","with torch.no_grad():\n","    output = model(input_tensor)['out'][0]  # shape: (21, H, W)\n","pred = torch.argmax(output, dim=0).numpy()\n","\n","segmap = decode_segmap(pred)\n","cv2_imshow(cv2.cvtColor(segmap, cv2.COLOR_RGB2BGR))"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}